<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>JoeyLLM | Australiaâ€™s First Fair Dinkum AI Language Model</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f9;
            color: #333;
            background-image: url('2wqp59t4zvfe1.jpeg');
            background-size: cover;
            background-position: center;
            background-attachment: fixed;
            backdrop-filter: blur(5px);
        }
        header {
            background-color: rgba(120, 134, 107, 0.7);
            color: white;
            padding: 20px;
            text-align: center;
        }
        header h1 { margin: 0; }
        .content {
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.8);
            border-radius: 8px;
            max-width: 800px;
            margin: 20px auto;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
        }
        .content h2 { color: #0055a5; }
        .content code { background-color: #eee; padding: 2px 4px; border-radius: 4px; }
        .content pre { background-color: #eee; padding: 10px; border-radius: 4px; overflow-x: auto; }
        footer {
            background-color: rgba(120, 134, 107, 0.7);
            color: white;
            text-align: center;
            padding: 15px;
            position: fixed;
            width: 100%;
            bottom: 0;
        }
    </style>
</head>
<body>
<header>
    <h1>JoeyLLM | Australiaâ€™s First Fair Dinkum AI Language Model</h1>
</header>
<div class="content">
    <h2>G'day, mate! ğŸ„â€â™‚ï¸ Welcome to JoeyLLM</h2>
    <p>Welcome to JoeyLLM, the next-gen Aussie AI that speaks your language â€“ whether it's English, Aussie slang, or even a bit of Strayan bush poetry.</p>
    <p>Weâ€™re on a mission to build Australiaâ€™s first culturally and linguistically tailored large language model (LLM). Unlike your regular AI that doesnâ€™t know the difference between a bottle-o and a servo, JoeyLLM will be trained on a rich dataset of Australian contexts, including indigenous languages, regional slang, and local knowledge.</p>
    <p>By the end of this project, we want JoeyLLM to be the <strong>Steve Irwin</strong> of AI â€“ smart, culturally aware, and ready to take on the world! ğŸŠ</p>

    <h2>ğŸŒ Why JoeyLLM?</h2>
    <p>Most AI models think <code>thongs</code> are flip-flops and that <code>football</code> means soccer. Not on our watch! ğŸš«âš½</p>
    <ul>
        <li><strong>âœ… Understands Aussie Culture</strong> â€“ Indigenous languages, regional dialects, and why we shorten every word.</li>
        <li><strong>âœ… Ethical AI</strong> â€“ No dodgy biases, just a fair go for all.</li>
        <li><strong>âœ… Open Source</strong> â€“ Because AI should be shared like a good backyard barbie.</li>
        <li><strong>âœ… Built for Australia</strong> â€“ Made for industries, universities, and the community (not just Silicon Valley).</li>
    </ul>

    <h2>ğŸš€ Project Goals</h2>
    <ul>
        <li>Build a scalable AI model that doesnâ€™t get confused when you say <code>Chuck a uey</code> ğŸ›»</li>
        <li>Publish open-source datasets and research (because weâ€™re not gatekeepers)</li>
        <li>Get industry, academia, and everyday Aussies involved in making AI actually useful Down Under</li>
    </ul>

    <h2>ğŸ—ï¸ Technical Foundation</h2>
    <p>JoeyLLM is powered by state-of-the-art transformer architectures, just like GPT, but with more Vegemite. ğŸ¥ª</p>
    <ul>
        <li>High-quality Australian datasets (yes, that includes regional footy banter)</li>
        <li>Fine-tuning for ethical AI (we wonâ€™t teach it to call everything a <code>drop bear</code>)</li>
        <li>Making it smart enough to handle real Australian language and culture</li>
    </ul>

    <h2>ğŸ¤ Get Involved</h2>
    <p>Reckon youâ€™ve got what it takes to help train an AI that knows the difference between <code>mate</code> and <code>maaate</code>? Join us!</p>
    <ul>
        <li>ğŸ“¢ <a href="https://github.com/JoeyLLM" target="_blank">GitHub Discussions</a></li>
        <li>ğŸ› ï¸ <a href="https://github.com/JoeyLLM/contribute" target="_blank">Contributing Guide</a></li>
        <li>ğŸ“„ <a href="https://github.com/JoeyLLM/wiki" target="_blank">Project Wiki</a></li>
    </ul>

    <h2>ğŸ‘¥ Meet the Team</h2>
    <p>We're a team of developers, researchers, and everyday Aussies passionate about making AI reflect the real Australia:</p>
    <ul>
        <li><strong>Erica Liu</strong> â€“ Project Manager & Human-Interactive Computing Specialist</li>
        <li><strong>Tom Smith</strong> â€“ NLP Engineer & Larrikin Language Lover</li>
        <li><strong>Sydney Tech Collective</strong> â€“ Community Partner</li>
    </ul>

    <h2>ğŸ§ª Try It Out (Coming Soon!)</h2>
    <p>Weâ€™re working on a web demo where you can chat with JoeyLLM in proper Aussie lingo. Stay tuned!</p>

    <h2>ğŸ—£ï¸ What People Are Saying</h2>
    <blockquote>
        <p>â€œFinally, an AI that gets what I mean when I say â€˜arvoâ€™!â€ â€“ Dr. Jen K., Linguist</p>
    </blockquote>

    
    <h2>ğŸ“… Project Roadmap</h2>
    <ul>
        <li><strong>March 2025</strong> â€“ Data collection begins</li>
        <li><strong>June 2025</strong> â€“ First LLM prototype trained</li>
        <li><strong>August 2025</strong> â€“ Open-source release of JoeyLLM v1</li>
        <li><strong>Ongoing</strong> â€“ Community contributions & fine-tuning</li>
    </ul>

    <h2>ğŸ” Navigating the Repo</h2>
    <p>Feel free to explore our <strong>main</strong> branch. Youâ€™ll find:</p>
    <ul>
        <li><code>docker/</code>: Docker workspace for containerized development.</li>
        <li><code>test/</code>: Test suites and scripts. <a href="https://github.com/southern-cross-ai/JoeyLLM/tree/main/test" target="_blank">View tests</a></li>
        <li><code>src/</code>: Model code structure (tokenizer, model, data, training). <a href="https://github.com/southern-cross-ai/JoeyLLM/tree/main/src" target="_blank">Browse src</a></li>
        <li><code>docs/</code>: Documentation, including <code>CONTRIBUTING</code> for detailed contribution guidelines.</li>
    </ul>
    <p><strong>Main</strong> is protectedâ€”fork, open a pull request, and weâ€™ll review within one business week before merging.</p>

    <h2>ğŸ“˜ GPT-2 Model Training Guide</h2>
    <p>This guide explains how to train the custom JoeyLLM GPT-2 model.</p>
    <h3>Prerequisites</h3>
    <ul>
        <li>Python 3.10+</li>
        <li>NVIDIA GPU with CUDA 12.4+ and PyTorch with GPU support</li>
        <li>Install required packages:
            <pre><code>pip install -r requirements.txt</code></pre>
        </li>
    </ul>
    <h3>Project Structure Overview</h3>
    <pre><code>JoeyLLM/
â”œâ”€â”€ main.py                     # Entry point: loads config and starts training
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # Repo overview
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile              # Container setup
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CONTRIBUTING            # Contribution guidelines
â”‚   â”œâ”€â”€ LICENSE                 # License file
â”‚   â””â”€â”€ train                   # Training docs
â”œâ”€â”€ test/
â”‚   â””â”€â”€ pre_run_test.py         # Sanity checks
â””â”€â”€ src/
    â”œâ”€â”€ configs/
    â”‚   â””â”€â”€ config.yaml         # Hydra configs
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ dataset.py          # Dataset loader
    â”‚   â”œâ”€â”€ test_data.py        # Validation/test data
    â”‚   â””â”€â”€ chunk.py            # Data chunking
    â”œâ”€â”€ model/
    â”‚   â”œâ”€â”€ joeyllm.py          # Custom GPT-2 model
    â”‚   â””â”€â”€ test_model.py       # Model tests
    â”œâ”€â”€ tokenizer/
    â”‚   â”œâ”€â”€ train_tokenizer.py  # Tokenizer training
    â”‚   â””â”€â”€ test_tokenizer.py   # Tokenizer tests
    â””â”€â”€ train/
        â”œâ”€â”€ loop.py             # Training loop
        â””â”€â”€ optimizer.py        # Optimizer setup
</code></pre>
    <h3>Monitor with Weights & Biases</h3>
    <p>Before training, login:<br><code>wandb login</code></p>
    <h3>Training on Single GPU</h3>
    <pre><code>python src/main.py</code></pre>
    <p>This will load the model, load 25% of the dataset, start training with W&B logging, and save checkpoints each epoch.</p>

    <p style="text-align: center; font-size: 2em;">ğŸ¦˜</p>
    <p style="text-align: center;">(Joeyâ€™s keeping an eye on you while you scroll!)</p>
</div>
<footer>
    <p>Made with love by JoeyLLM Team ğŸ‡¦ğŸ‡º</p>
</footer>
</body>
</html>
